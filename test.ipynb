{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleKeywordTableIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import os \n",
    "from pathlib import Path\n",
    "from llama_index.embeddings.llamafile import LlamafileEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import load_index_from_storage, StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model=\"llama3.1:latest\", request_timeout=120.0)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "parser = LlamaParse(\n",
    "    api_key=\"llx-\",\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "node_parser = SentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue to us during the daytime because of a phenomenon called scattering. Here's what happens:\n",
      "\n",
      "1.  **Sunlight and Atmosphere:** When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2). These molecules are much smaller than the wavelength of light.\n",
      "\n",
      "2.  **Scattering of Light:** The shorter wavelengths of light, like blue and violet, scatter off these gas molecules in all directions. This is known as Rayleigh scattering, named after the British physicist Lord Rayleigh who first described it. Blue light is scattered more than red light because its wavelength is smaller, so there are more opportunities for scattering to occur.\n",
      "\n",
      "3.  **Why We See a Blue Sky:** When we look up at the sky on a clear day, we see this scattered blue light coming from all directions. The Earth's atmosphere acts as a prism, dispersing the sunlight and making it appear blue. The amount of scattering that occurs depends on the wavelength of the light.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "response = ollama.chat(model='llama3.1:latest', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.909305694Z\",\"message\":{\"role\":\"assistant\",\"content\":\"Hello\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.920220804Z\",\"message\":{\"role\":\"assistant\",\"content\":\"!\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.927173708Z\",\"message\":{\"role\":\"assistant\",\"content\":\" It\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.934101803Z\",\"message\":{\"role\":\"assistant\",\"content\":\"'s\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.941054889Z\",\"message\":{\"role\":\"assistant\",\"content\":\" nice\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.948035346Z\",\"message\":{\"role\":\"assistant\",\"content\":\" to\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.95489135Z\",\"message\":{\"role\":\"assistant\",\"content\":\" meet\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.9617542Z\",\"message\":{\"role\":\"assistant\",\"content\":\" you\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.968584414Z\",\"message\":{\"role\":\"assistant\",\"content\":\".\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.975476306Z\",\"message\":{\"role\":\"assistant\",\"content\":\" Is\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.982356838Z\",\"message\":{\"role\":\"assistant\",\"content\":\" there\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.989231782Z\",\"message\":{\"role\":\"assistant\",\"content\":\" something\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:50.996114251Z\",\"message\":{\"role\":\"assistant\",\"content\":\" I\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.002988713Z\",\"message\":{\"role\":\"assistant\",\"content\":\" can\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.009898457Z\",\"message\":{\"role\":\"assistant\",\"content\":\" help\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.016796507Z\",\"message\":{\"role\":\"assistant\",\"content\":\" you\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.023698164Z\",\"message\":{\"role\":\"assistant\",\"content\":\" with\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.030629049Z\",\"message\":{\"role\":\"assistant\",\"content\":\",\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.03753736Z\",\"message\":{\"role\":\"assistant\",\"content\":\" or\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.044462316Z\",\"message\":{\"role\":\"assistant\",\"content\":\" would\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.051375072Z\",\"message\":{\"role\":\"assistant\",\"content\":\" you\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.059815265Z\",\"message\":{\"role\":\"assistant\",\"content\":\" like\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.06681652Z\",\"message\":{\"role\":\"assistant\",\"content\":\" to\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.073815323Z\",\"message\":{\"role\":\"assistant\",\"content\":\" chat\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.080820283Z\",\"message\":{\"role\":\"assistant\",\"content\":\"?\"},\"done\":false}\n",
      "{\"model\":\"llama3.1:latest\",\"created_at\":\"2024-09-25T09:49:51.087729777Z\",\"message\":{\"role\":\"assistant\",\"content\":\"\"},\"done_reason\":\"stop\",\"done\":true,\"total_duration\":1301336033,\"load_duration\":1097488279,\"prompt_eval_count\":12,\"prompt_eval_duration\":22755000,\"eval_count\":26,\"eval_duration\":178436000}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 3204812d-9d35-4af8-8d94-164b3c9a2442\n",
      "Started parsing the file under job_id e0e6203b-6923-45fb-bf41-1632dbcb7ab2\n",
      ".Started parsing the file under job_id 81d5b2cd-1b76-4e10-9a88-e65e34318501\n",
      ".Started parsing the file under job_id 1565237c-d40b-4c45-af64-6a8d92006131\n",
      "Started parsing the file under job_id 832e6877-695c-4f23-b3f7-edf64b1e8d79\n",
      ".Started parsing the file under job_id 205af550-8517-4705-af25-7812915da43f\n",
      "Started parsing the file under job_id 8052a58d-935a-460e-b9ec-a2f322135d86\n",
      "Error while parsing the file './data/pdf/ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems.pdf': \n",
      "Started parsing the file under job_id 5dddee1c-2723-49cc-991c-5737513b41d4\n",
      "Started parsing the file under job_id 77741485-ca15-4653-98b4-5eba6e6ffee8\n",
      "Started parsing the file under job_id 6ff5ab27-1c0f-4818-bcbf-84da3d506e8b\n",
      "..........Started parsing the file under job_id b6dd4548-34a4-4e79-9203-57b104190ed1\n",
      "Started parsing the file under job_id 8357df31-a10a-45b6-b5b8-b471cfb11c5f\n",
      "...Error while parsing the file './data/pdf/Exploring Advanced Large Language Models with LLMsuite.pdf': \n",
      "Started parsing the file under job_id 6288415c-678a-4a06-b322-a80c29b5f5c8\n",
      ".Started parsing the file under job_id 83cf8cf8-461f-46f0-87d2-47744a17a373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "paper_titles = os.listdir('./data/pdf')\n",
    "paper_titles = [title.split('.pdf')[0] for title in paper_titles if title.endswith('.pdf')]\n",
    "city_docs = {}\n",
    "for paper_title in paper_titles:\n",
    "    city_docs[paper_title] = parser.load_data(f\"./data/pdf/{paper_title}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_index = {}\n",
    "for paper_title in paper_titles:\n",
    "\n",
    "    # build index\n",
    "    paper_index[paper_title] = VectorStoreIndex.from_documents(city_docs[paper_title])\n",
    "\n",
    "    # persist index\n",
    "    paper_index[paper_title].storage_context.persist(persist_dir=f\"./storage/{paper_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Build agents dictionary\n",
    "agents = {}\n",
    "query_engines = {}\n",
    "\n",
    "# this is for the baseline\n",
    "all_nodes = []\n",
    "\n",
    "\n",
    "for idx, paper_title in enumerate(paper_titles):\n",
    "    nodes = node_parser.get_nodes_from_documents(city_docs[paper_title])\n",
    "    all_nodes.extend(nodes)\n",
    "\n",
    "    if not os.path.exists(f\"./data/{paper_title}\"):\n",
    "        # build vector index\n",
    "        vector_index = VectorStoreIndex(nodes)\n",
    "        vector_index.storage_context.persist(\n",
    "            persist_dir=f\"./data/{paper_title}\"\n",
    "        )\n",
    "    else:\n",
    "        vector_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=f\"./data/{paper_title}\"),\n",
    "        )\n",
    "\n",
    "    # build summary index\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    \n",
    "    # define query engines\n",
    "    vector_query_engine = vector_index.as_query_engine(llm=Settings.llm)\n",
    "    summary_query_engine = summary_index.as_query_engine(llm=Settings.llm)\n",
    "\n",
    "    # define tools\n",
    "    query_engine_tools = [\n",
    "        QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"vector_tool\",\n",
    "                description = (\n",
    "        f\"Useful for answering questions about the academic paper titled '{paper_title}'. \"\n",
    "        \"This tool can provide information on various aspects of the paper, including but not limited to:\"\n",
    "        \"\\n- The main research question or hypothesis\"\n",
    "        \"\\n- Methodology and experimental design\"\n",
    "        \"\\n- Key findings and results\"\n",
    "        \"\\n- Theoretical framework and background\"\n",
    "        \"\\n- Implications and conclusions\"\n",
    "        \"\\n- Related work and literature review\"\n",
    "        \"\\n- Limitations and future research directions\"\n",
    "        \"\\nUse a specific question about the paper as input to this tool.\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        QueryEngineTool(\n",
    "            query_engine=summary_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"summary_tool\",\n",
    "                description=(\n",
    "                    \"Useful for any requests that require a holistic summary\"\n",
    "                    f\" of EVERYTHING about {paper_title}. For questions about\"\n",
    "                    \" more specific sections, please use the vector_tool.\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # build agent\n",
    "    function_llm = Ollama(model=\"llama3:latest\", request_timeout=120.0)\n",
    "    agent = ReActAgent.from_tools(\n",
    "        \n",
    "        query_engine_tools,\n",
    "        max_iterations=100,\n",
    "        llm=function_llm,\n",
    "        verbose=True,\n",
    "        system_prompt=f\"\"\"\\\n",
    "You are a specialized agent designed to answer queries about {paper_title}.\n",
    "You must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "    agents[paper_title] = agent\n",
    "    query_engines[paper_title] = vector_index.as_query_engine(\n",
    "        similarity_top_k=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lyft',\n",
       " 'A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph',\n",
       " 'Exploring Advanced Large Language Models with LLMsuite',\n",
       " 'Toolformer: Language Models Can Teach Themselves to Use Tools',\n",
       " 'Learning Transferable Visual Models From Natural Language Supervision',\n",
       " 'ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems',\n",
       " 'Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models',\n",
       " 'ColPali: Efficient Document Retrieval with Vision Language Models',\n",
       " 'LoRA: Low-Rank Adaptation of Large Language Models',\n",
       " 'Graph Retrieval-Augmented Generation: A Survey',\n",
       " 'uber',\n",
       " 'Deep Time Series Models: A Comprehensive Survey and Benchmark']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tool for each document agent\n",
    "all_tools = []\n",
    "for paper_title in paper_titles:\n",
    "    paper_summary = (\n",
    "        f\"This content contains paper articles about {paper_title}. Use\"\n",
    "        f\" this tool if you want to answer any questions about {paper_title}.\\n\"\n",
    "    )\n",
    "    doc_tool = QueryEngineTool(\n",
    "        query_engine=agents[paper_title],\n",
    "        metadata=ToolMetadata(\n",
    "            name=f\"tool_{paper_title}\",\n",
    "            description=paper_summary,\n",
    "        ),\n",
    "    )\n",
    "    all_tools.append(doc_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an \"object\" index and retriever over these tools\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")\n",
    "\n",
    "top_agent = ReActAgent.from_tools(\n",
    "    max_iterations=100,\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=3),\n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries about a set of given paper.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step fef80232-14d6-49a2-b4d6-1f0c056bc84d. Step input: Tell me about ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: tool_ReDel\n",
      "Action Input: {'input': 'ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: No such tool named `tool_ReDel`.\n",
      "\u001b[0m> Running step d16350ac-b131-4792-b4a1-19c7d65ee9cf. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The user pointed out that there is no such tool as `tool_ReDel`. I need to use a different tool.\n",
      "Action: tool_A\n",
      "Action Input: {'input': 'ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: No such tool named `tool_A`.\n",
      "\u001b[0m> Running step 1f2c156b-b5c5-4b5f-bd51-91afe1659555. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The user pointed out that there is no such tool as `tool_A`. I need to try another option.\n",
      "Action: tool_ReDel\n",
      "Action Input: {'input': 'ReDel: A Toolkit for LMM-Powered Recursive Multi-Agent Systems', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: No such tool named `tool_ReDel`.\n",
      "\u001b[0m> Running step deca8714-9a2d-4880-a3db-4cee0deb4088. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: It seems that there is no tool that matches the name \"tool_ReDel\". I'll try again.\n",
      "Action: tool_Optimizing\n",
      "Action Input: {'input': 'ReDel: A Toolkit for LMM-Powered Recursive Multi-Agent Systems', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: No such tool named `tool_Optimizing`.\n",
      "\u001b[0m> Running step 6b1cf1b4-609b-4096-8615-dd61daf8aa87. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: None of the provided tools seem to match the name \"ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems\". I'll try to provide an answer based on my knowledge.\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Unfortunately, it seems that there is no information available about \"ReDel: A Toolkit for LMM-Powered Recursive Multi-Agent Systems\" as none of the provided tools match this name.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = top_agent.query(\"Tell me about ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=f\"./storage/all_datas\"),\n",
    "        )\n",
    "\n",
    "#base_index.storage_context.persist(persist_dir=f\"./storage/all_datas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_query_engine = base_index.as_query_engine(similarity_top_k=4)\n",
    "response = base_query_engine.query(\"Tell me detail about ColPali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = base_query_engine.query(\"I wnat to know convex hull's solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To find the convex hull of a set of points, you first need to sort them in either clockwise or counterclockwise order. This can be done using comparison-based sorting algorithms like quicksort or mergesort. However, if you have a large number of points and memory is a concern, you might want to consider an efficient sorting algorithm that doesn't require extra space.\\n\\nAfter sorting the points, you'll need to iterate through them to build the convex hull. The key insight here is to keep track of the upper and lower points as you go, and to remove any point that lies below the line formed by the two most recently added points.\\n\\nOne efficient way to implement this step is to use a sweep line algorithm or a stack-based approach. The basic idea behind these algorithms is to maintain a list of active points (i.e., those that are part of the convex hull) as you scan through all the points in order.\\n\\nIn more detail, when adding a new point to the convex hull, if it's left of the current topmost point and higher than it, or right of the current bottommost point and lower than it, then we can simply add it to the list. If not, then we have to remove the topmost point (if it lies below the line formed by the new point and the previous topmost point) or the bottommost point (if it lies above the line formed by the new point and the previous bottommost point), until one of them meets these criteria.\\n\\nThis solution has a time complexity that's linear with respect to the number of points, assuming you can sort them efficiently.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id f02fed19-4046-401d-a213-a4aef473d9b9\n"
     ]
    }
   ],
   "source": [
    "docs = parser.load_data('data/pdf/筆記.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'\\xfd7zXZ'\n",
      "incorrect startxref pointer(1)\n",
      "invalid pdf header: b'\\xfd7zXZ'\n",
      "incorrect startxref pointer(1)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "Settings.llm = Ollama(model=\"llama3:latest\", request_timeout=120.0)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/lyft\"\n",
    "    )\n",
    "    lyft_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/uber\"\n",
    "    )\n",
    "    uber_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False\n",
    "\n",
    "if not index_loaded:\n",
    "    # load data\n",
    "    lyft_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
    "    ).load_data()\n",
    "    uber_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/uber_2021.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
    "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
    "\n",
    "    # persist index\n",
    "    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\n",
    "    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    llm=Settings.llm,\n",
    "    verbose=True,\n",
    "    # context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e1b5553b-b1df-4aeb-a358-d8bba1264489. Step input: What was Lyft's revenue growth in 2021?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "Action: lyft_10k\n",
      "Action Input: {'input': \"Lyft's revenue growth in 2021\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Lyft's revenue reached an all-time high in the three months ended December 31, 2021, increasing compared to the previous quarter. This was driven by an increase in ride frequency and a shift toward higher revenue rides, as well as revenues from licensing and data access agreements.\n",
      "\u001b[0m> Running step 116365d0-e809-4e65-aee9-4b2b14b9b925. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Lyft experienced significant revenue growth in 2021, specifically in the last quarter of the year, due to increased ride frequency and a shift towards higher-revenue rides, as well as revenues from licensing and data access agreements.\n",
      "\u001b[0mLyft experienced significant revenue growth in 2021, specifically in the last quarter of the year, due to increased ride frequency and a shift towards higher-revenue rides, as well as revenues from licensing and data access agreements.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = agent.chat(\"What was Lyft's revenue growth in 2021?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lyft\n",
      "<llama_index.core.indices.vector_store.base.VectorStoreIndex object at 0x7451306659c0>\n",
      "A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph\n",
      "<llama_index.core.indices.vector_store.base.VectorStoreIndex object at 0x745130665de0>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VectorStoreIndex' object has no attribute 'id_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     vector_index \u001b[38;5;241m=\u001b[39m temp_vector_index\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mvector_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_vector_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/core/indices/base.py:209\u001b[0m, in \u001b[0;36mBaseIndex.insert\u001b[0;34m(self, document, **insert_kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Insert a document.\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\u001b[38;5;241m.\u001b[39mas_trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsert\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 209\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[43mrun_transformations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minsert_nodes(nodes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minsert_kwargs)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocstore\u001b[38;5;241m.\u001b[39mset_document_hash(document\u001b[38;5;241m.\u001b[39mget_doc_id(), document\u001b[38;5;241m.\u001b[39mhash)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/core/ingestion/pipeline.py:100\u001b[0m, in \u001b[0;36mrun_transformations\u001b[0;34m(nodes, transformations, in_place, cache, cache_collection, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m             cache\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;28mhash\u001b[39m, nodes, collection\u001b[38;5;241m=\u001b[39mcache_collection)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nodes\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:265\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspan_enter(\n\u001b[1;32m    258\u001b[0m     id_\u001b[38;5;241m=\u001b[39mid_,\n\u001b[1;32m    259\u001b[0m     bound_args\u001b[38;5;241m=\u001b[39mbound_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent(SpanDropEvent(span_id\u001b[38;5;241m=\u001b[39mid_, err_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e)))\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/core/node_parser/interface.py:193\u001b[0m, in \u001b[0;36mNodeParser.__call__\u001b[0;34m(self, nodes, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, nodes: Sequence[BaseNode], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_nodes_from_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/core/node_parser/interface.py:160\u001b[0m, in \u001b[0;36mNodeParser.get_nodes_from_documents\u001b[0;34m(self, documents, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_nodes_from_documents\u001b[39m(\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    149\u001b[0m     documents: Sequence[Document],\n\u001b[1;32m    150\u001b[0m     show_progress: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse documents into nodes.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     doc_id_to_document \u001b[38;5;241m=\u001b[39m {doc\u001b[38;5;241m.\u001b[39mid_: doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents}\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    163\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mNODE_PARSING, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mDOCUMENTS: documents}\n\u001b[1;32m    164\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m    165\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_nodes(documents, show_progress\u001b[38;5;241m=\u001b[39mshow_progress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/llama_index/core/node_parser/interface.py:160\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_nodes_from_documents\u001b[39m(\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    149\u001b[0m     documents: Sequence[Document],\n\u001b[1;32m    150\u001b[0m     show_progress: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[BaseNode]:\n\u001b[1;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse documents into nodes.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     doc_id_to_document \u001b[38;5;241m=\u001b[39m {\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid_\u001b[49m: doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents}\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m    163\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mNODE_PARSING, payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mDOCUMENTS: documents}\n\u001b[1;32m    164\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[1;32m    165\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_nodes(documents, show_progress\u001b[38;5;241m=\u001b[39mshow_progress, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorStoreIndex' object has no attribute 'id_'"
     ]
    }
   ],
   "source": [
    "\n",
    "paper_titles = os.listdir('./storage')\n",
    "vector_index = None\n",
    "for paper_title in paper_titles:\n",
    "    temp_vector_index = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=f\"./storage/{paper_title}\"),\n",
    "    )\n",
    "    temp_vector_index.node\n",
    "    print(paper_title)\n",
    "    print(temp_vector_index)\n",
    "    if vector_index is None:\n",
    "        vector_index = temp_vector_index\n",
    "    else:\n",
    "        vector_index.insert(temp_vector_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(vector_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
