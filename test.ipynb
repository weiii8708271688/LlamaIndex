{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleKeywordTableIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.schema import IndexNode\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "import os \n",
    "from pathlib import Path\n",
    "from llama_index.embeddings.llamafile import LlamafileEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import load_index_from_storage, StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model=\"llama3.1:latest\", request_timeout=120.0)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id fb751ad6-26f6-4db9-b14b-956e5921366c\n",
      "......Started parsing the file under job_id 88c5b2e8-e7dd-4139-8ea9-3ab69f2631d6\n",
      "..Started parsing the file under job_id 033ea0f3-2d41-4d33-bccf-c36aa806f74e\n",
      ".Started parsing the file under job_id 237f0354-faaa-495d-85f3-3f8c6cc37449\n",
      ".Started parsing the file under job_id 0ee474aa-50cf-41bb-9de7-855431f4e7b3\n",
      ".Started parsing the file under job_id 5c482d0a-9c2d-465e-9c53-e74e1f23ecc5\n",
      "...Started parsing the file under job_id 946f8c7c-1eb2-417b-be7b-ee9830404351\n",
      "..Started parsing the file under job_id b004e957-dcbf-4524-93e2-e848d7d7ebf7\n",
      "Started parsing the file under job_id 6ddfe698-4dc3-4316-8fa3-183d40cf5288\n",
      "..Started parsing the file under job_id 5f9fb45c-4d95-49a7-9b55-e739eae9b598\n",
      "...."
     ]
    }
   ],
   "source": [
    "parser = LlamaParse(\n",
    "    api_key=\"llx-\",\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "paper_titles = os.listdir('./data/pdf')\n",
    "paper_titles = [title.split('.pdf')[0] for title in paper_titles if title.endswith('.pdf')]\n",
    "city_docs = {}\n",
    "for paper_title in paper_titles:\n",
    "    city_docs[paper_title] = parser.load_data(f\"./data/pdf/{paper_title}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_index = {}\n",
    "for paper_title in paper_titles:\n",
    "\n",
    "    # build index\n",
    "    paper_index[paper_title] = VectorStoreIndex.from_documents(city_docs[paper_title])\n",
    "\n",
    "    # persist index\n",
    "    paper_index[paper_title].storage_context.persist(persist_dir=f\"./storage/{paper_title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter()\n",
    "\n",
    "\n",
    "# Build agents dictionary\n",
    "agents = {}\n",
    "query_engines = {}\n",
    "\n",
    "# this is for the baseline\n",
    "all_nodes = []\n",
    "\n",
    "\n",
    "for idx, paper_title in enumerate(paper_titles):\n",
    "    nodes = node_parser.get_nodes_from_documents(city_docs[paper_title])\n",
    "    all_nodes.extend(nodes)\n",
    "\n",
    "    if not os.path.exists(f\"./data/{paper_title}\"):\n",
    "        # build vector index\n",
    "        vector_index = VectorStoreIndex(nodes)\n",
    "        vector_index.storage_context.persist(\n",
    "            persist_dir=f\"./data/{paper_title}\"\n",
    "        )\n",
    "    else:\n",
    "        vector_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=f\"./data/{paper_title}\"),\n",
    "        )\n",
    "\n",
    "    # build summary index\n",
    "    summary_index = SummaryIndex(nodes)\n",
    "    \n",
    "    # define query engines\n",
    "    vector_query_engine = vector_index.as_query_engine(llm=Settings.llm)\n",
    "    summary_query_engine = summary_index.as_query_engine(llm=Settings.llm)\n",
    "\n",
    "    # define tools\n",
    "    query_engine_tools = [\n",
    "        QueryEngineTool(\n",
    "            query_engine=vector_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"vector_tool\",\n",
    "                description = (\n",
    "        f\"Useful for answering questions about the academic paper titled '{paper_title}'. \"\n",
    "        \"This tool can provide information on various aspects of the paper, including but not limited to:\"\n",
    "        \"\\n- The main research question or hypothesis\"\n",
    "        \"\\n- Methodology and experimental design\"\n",
    "        \"\\n- Key findings and results\"\n",
    "        \"\\n- Theoretical framework and background\"\n",
    "        \"\\n- Implications and conclusions\"\n",
    "        \"\\n- Related work and literature review\"\n",
    "        \"\\n- Limitations and future research directions\"\n",
    "        \"\\nUse a specific question about the paper as input to this tool.\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        QueryEngineTool(\n",
    "            query_engine=summary_query_engine,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"summary_tool\",\n",
    "                description=(\n",
    "                    \"Useful for any requests that require a holistic summary\"\n",
    "                    f\" of EVERYTHING about {paper_title}. For questions about\"\n",
    "                    \" more specific sections, please use the vector_tool.\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # build agent\n",
    "    function_llm = Ollama(model=\"llama3:latest\", request_timeout=120.0)\n",
    "    agent = ReActAgent.from_tools(\n",
    "        \n",
    "        query_engine_tools,\n",
    "        max_iterations=100,\n",
    "        llm=function_llm,\n",
    "        verbose=True,\n",
    "        system_prompt=f\"\"\"\\\n",
    "You are a specialized agent designed to answer queries about {paper_title}.\n",
    "You must ALWAYS use at least one of the tools provided when answering a question; do NOT rely on prior knowledge.\\\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "    agents[paper_title] = agent\n",
    "    query_engines[paper_title] = vector_index.as_query_engine(\n",
    "        similarity_top_k=2\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tool for each document agent\n",
    "all_tools = []\n",
    "for paper_title in paper_titles:\n",
    "    paper_summary = (\n",
    "        f\"This content contains paper articles about {paper_title}. Use\"\n",
    "        f\" this tool if you want to answer any questions about {paper_title}.\\n\"\n",
    "    )\n",
    "    doc_tool = QueryEngineTool(\n",
    "        query_engine=agents[paper_title],\n",
    "        metadata=ToolMetadata(\n",
    "            name=f\"tool_{paper_title}\",\n",
    "            description=paper_summary,\n",
    "        ),\n",
    "    )\n",
    "    all_tools.append(doc_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an \"object\" index and retriever over these tools\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    all_tools,\n",
    "    index_cls=VectorStoreIndex,\n",
    ")\n",
    "\n",
    "top_agent = ReActAgent.from_tools(\n",
    "    max_iterations=100,\n",
    "    tool_retriever=obj_index.as_retriever(similarity_top_k=3),\n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries about a set of given paper.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step fef80232-14d6-49a2-b4d6-1f0c056bc84d. Step input: Tell me about ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: tool_ReDel\n",
      "Action Input: {'input': 'ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: No such tool named `tool_ReDel`.\n",
      "\u001b[0m> Running step d16350ac-b131-4792-b4a1-19c7d65ee9cf. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The user pointed out that there is no such tool as `tool_ReDel`. I need to use a different tool.\n",
      "Action: tool_A\n",
      "Action Input: {'input': 'ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: No such tool named `tool_A`.\n",
      "\u001b[0m> Running step 1f2c156b-b5c5-4b5f-bd51-91afe1659555. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The user pointed out that there is no such tool as `tool_A`. I need to try another option.\n",
      "Action: tool_ReDel\n",
      "Action Input: {'input': 'ReDel: A Toolkit for LMM-Powered Recursive Multi-Agent Systems', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: No such tool named `tool_ReDel`.\n",
      "\u001b[0m> Running step deca8714-9a2d-4880-a3db-4cee0deb4088. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: It seems that there is no tool that matches the name \"tool_ReDel\". I'll try again.\n",
      "Action: tool_Optimizing\n",
      "Action Input: {'input': 'ReDel: A Toolkit for LMM-Powered Recursive Multi-Agent Systems', 'num_beams': 5}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: No such tool named `tool_Optimizing`.\n",
      "\u001b[0m> Running step 6b1cf1b4-609b-4096-8615-dd61daf8aa87. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: None of the provided tools seem to match the name \"ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems\". I'll try to provide an answer based on my knowledge.\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Unfortunately, it seems that there is no information available about \"ReDel: A Toolkit for LMM-Powered Recursive Multi-Agent Systems\" as none of the provided tools match this name.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = top_agent.query(\"Tell me about ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_index = VectorStoreIndex(all_nodes)\n",
    "base_query_engine = base_index.as_query_engine(similarity_top_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = base_query_engine.query(\"Tell me about ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ReDel is a toolkit for working with recursive multi-agent systems that supports custom tool-use, delegation schemes, event-based logging, and interactive replay in an easy-to-use web interface. It allows developers to quickly build, iterate on, and run experiments involving dynamic multi-agent systems. The toolkit is fully open-source and free to use under the MIT license.\\n\\nReDel provides a modular interface to create tools for agents to use, an event framework to instrument experiments for later analysis, and a web interface to interact with and explore developer-defined systems. It also offers best-in-class support for system visualization and modern LLMs with tool usage.\\n\\nThe toolkit has been used to demonstrate recursive multi-agent systems' performance on three diverse benchmarks: FanOutQA, TravelPlanner, and WebArena. The results show that ReDel's recursive delegation system significantly outperforms its corresponding single-agent baseline across all benchmarks, even surpassing the previous state-of-the-art systems in some cases.\\n\\nReDel has also been used to analyze the failure cases of recursive multi-agent systems, including overcommitment and undercommitment. These findings can help inform the development of future interventions that target these behaviors to improve system performance.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'\\xfd7zXZ'\n",
      "incorrect startxref pointer(1)\n",
      "invalid pdf header: b'\\xfd7zXZ'\n",
      "incorrect startxref pointer(1)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "Settings.llm = Ollama(model=\"llama3:latest\", request_timeout=120.0)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/lyft\"\n",
    "    )\n",
    "    lyft_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/uber\"\n",
    "    )\n",
    "    uber_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False\n",
    "\n",
    "if not index_loaded:\n",
    "    # load data\n",
    "    lyft_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
    "    ).load_data()\n",
    "    uber_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/uber_2021.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
    "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
    "\n",
    "    # persist index\n",
    "    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\n",
    "    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.agent import ReActAgent\n",
    "\n",
    "agent = ReActAgent.from_tools(\n",
    "    query_engine_tools,\n",
    "    llm=Settings.llm,\n",
    "    verbose=True,\n",
    "    # context=context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step e1b5553b-b1df-4aeb-a358-d8bba1264489. Step input: What was Lyft's revenue growth in 2021?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "Action: lyft_10k\n",
      "Action Input: {'input': \"Lyft's revenue growth in 2021\"}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Lyft's revenue reached an all-time high in the three months ended December 31, 2021, increasing compared to the previous quarter. This was driven by an increase in ride frequency and a shift toward higher revenue rides, as well as revenues from licensing and data access agreements.\n",
      "\u001b[0m> Running step 116365d0-e809-4e65-aee9-4b2b14b9b925. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Lyft experienced significant revenue growth in 2021, specifically in the last quarter of the year, due to increased ride frequency and a shift towards higher-revenue rides, as well as revenues from licensing and data access agreements.\n",
      "\u001b[0mLyft experienced significant revenue growth in 2021, specifically in the last quarter of the year, due to increased ride frequency and a shift towards higher-revenue rides, as well as revenues from licensing and data access agreements.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = agent.chat(\"What was Lyft's revenue growth in 2021?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
